

<feed xmlns="http://www.w3.org/2005/Atom">
  <id>http://localhost:4000/</id>
  <title>MM-LLMs</title>
  <subtitle>A website to search the latest advances in the research of MM-LLMs.</subtitle>
  <updated>2024-02-20T08:21:12+09:00</updated>
  <author>
    <name>MM-LLMs</name>
    <uri>http://localhost:4000/</uri>
  </author>
  <link rel="self" type="application/atom+xml" href="http://localhost:4000/feed.xml"/>
  <link rel="alternate" type="text/html" hreflang="en"
    href="http://localhost:4000/"/>
  <generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator>
  <rights> Â© 2024 MM-LLMs </rights>
  <icon>/assets/img/favicons/favicon.ico</icon>
  <logo>/assets/img/favicons/favicon-96x96.png</logo>


  
  <entry>
    <title>Video-LLaMA</title>
    <link href="http://localhost:4000/posts/Video-LLaMA/" rel="alternate" type="text/html" title="Video-LLaMA" />
    <published>2023-06-05T01:00:00+09:00</published>
  
    <updated>2023-06-05T01:00:00+09:00</updated>
  
    <id>http://localhost:4000/posts/Video-LLaMA/</id>
    <content src="http://localhost:4000/posts/Video-LLaMA/" />
    <author>
      <name>Anonym</name>
    </author>

  
    
    <category term="EMNLP 2023" />
    
  

  
    <summary>
      





      
  Paper: Video-LLaMA: An Instruction-tuned Audio-Visual Language Model for Video Understanding
  GitHub Link
  Publisher: EMNLP 2023
  Author Affiliation: Alibaba Group
  Functional Division
    
      Understanding
      Generation
    
  
  Design Division
    
      Tool-using
      End-to-end
    
  
  Input Modalities $\rightarrow$ Output Modalities (I: Image, V: Video, A: Audio, 3D: Poin...
    </summary>
  

  </entry>

  
  <entry>
    <title>LLaVA-Med</title>
    <link href="http://localhost:4000/posts/LLaVA-Med/" rel="alternate" type="text/html" title="LLaVA-Med" />
    <published>2023-06-01T01:00:00+09:00</published>
  
    <updated>2023-06-01T01:00:00+09:00</updated>
  
    <id>http://localhost:4000/posts/LLaVA-Med/</id>
    <content src="http://localhost:4000/posts/LLaVA-Med/" />
    <author>
      <name>Anonym</name>
    </author>

  
    
    <category term="Arxiv" />
    
  

  
    <summary>
      





      
  Paper: LLaVA-Med: Training a Large Language-and-Vision Assistant for Biomedicine in One Day
  GitHub Link
  Publisher: Arxiv
  Author Affiliation: Microsoft
  Functional Division
    
      Understanding
      Generation
    
  
  Design Division
    
      Tool-using
      End-to-end
    
  
  Input Modalities $\rightarrow$ Output Modalities (I: Image, V: Video, A: Audio, 3D: Point Cloud, T...
    </summary>
  

  </entry>

  
  <entry>
    <title>PaLI-X</title>
    <link href="http://localhost:4000/posts/PaLI-X/" rel="alternate" type="text/html" title="PaLI-X" />
    <published>2023-05-29T01:00:00+09:00</published>
  
    <updated>2023-05-29T01:00:00+09:00</updated>
  
    <id>http://localhost:4000/posts/PaLI-X/</id>
    <content src="http://localhost:4000/posts/PaLI-X/" />
    <author>
      <name>Anonym</name>
    </author>

  
    
    <category term="Arxiv" />
    
  

  
    <summary>
      





      
  Paper: PaLI-X: On scaling up a multilingual vision and language model
  GitHub Link: None
  Publisher: Arxiv
  Author Affiliation: Google Research
  Functional Division
    
      Understanding
      Generation
    
  
  Design Division
    
      Tool-using
      End-to-end
    
  
  Input Modalities $\rightarrow$ Output Modalities (I: Image, V: Video, A: Audio, 3D: Point Cloud, T: Text)
  ...
    </summary>
  

  </entry>

  
  <entry>
    <title>GILL</title>
    <link href="http://localhost:4000/posts/GILL/" rel="alternate" type="text/html" title="GILL" />
    <published>2023-05-26T01:00:00+09:00</published>
  
    <updated>2023-05-26T01:00:00+09:00</updated>
  
    <id>http://localhost:4000/posts/GILL/</id>
    <content src="http://localhost:4000/posts/GILL/" />
    <author>
      <name>Anonym</name>
    </author>

  
    
    <category term="NIPS 2023" />
    
  

  
    <summary>
      





      
  Paper: Generating Images with Multimodal Language Models
  GitHub Link
  Publisher: NIPS 2023
  Author Affiliation: Carnegie Mellon University
  Functional Division
    
      Understanding
      Generation
    
  
  Design Division
    
      Tool-using
      End-to-end
    
  
  Input Modalities $\rightarrow$ Output Modalities (I: Image, V: Video, A: Audio, 3D: Point Cloud, T: Text)
    
 ...
    </summary>
  

  </entry>

  
  <entry>
    <title>PandaGPT</title>
    <link href="http://localhost:4000/posts/PandaGPT/" rel="alternate" type="text/html" title="PandaGPT" />
    <published>2023-05-25T01:00:00+09:00</published>
  
    <updated>2023-05-25T01:00:00+09:00</updated>
  
    <id>http://localhost:4000/posts/PandaGPT/</id>
    <content src="http://localhost:4000/posts/PandaGPT/" />
    <author>
      <name>Anonym</name>
    </author>

  
    
    <category term="Arxiv" />
    
  

  
    <summary>
      





      
  Paper: PandaGPT: One Model To Instruction-Follow Them All
  GitHub Link
  Publisher: Arxiv
  Author Affiliation: University of Cambridge
  Functional Division
    
      Understanding
      Generation
    
  
  Design Division
    
      Tool-using
      End-to-end
    
  
  Input Modalities $\rightarrow$ Output Modalities (I: Image, V: Video, A: Audio, 3D: Point Cloud, T: Text)
    
      I...
    </summary>
  

  </entry>

</feed>


